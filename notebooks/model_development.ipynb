{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import wandb\n",
    "\n",
    "sys.path.append(\"../\")  # go to parent dir\n",
    "\n",
    "from pprint import pprint\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import torch\n",
    "\n",
    "from lightning.pytorch import seed_everything, Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "from core.config import (\n",
    "    BATCH_SIZE,\n",
    "    LR,\n",
    "    N_EPOCHS,\n",
    "    RANDOM_STATE,\n",
    "    SAMPLE_RATE,\n",
    "    WEIGHT_DECAY,\n",
    ")\n",
    "from core.data import load_data\n",
    "from core.downstream import LightningMLP\n",
    "from core.transforms import load_transforms\n",
    "from core.upstream import load_feature_extractor, load_processor\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training script\n",
    "\n",
    "We will dissect the ```core.train``` script using the tiny Whisper model as an example\n",
    "\n",
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "\tdataset: nort3160\n",
      "\tmodel_id: whisper_tiny\n",
      "\tdtype: speech\n",
      "\tmax_duration: 10\n",
      "\ttransform: True\n",
      "\tdevice: cuda:0\n",
      "\tlr: 0.00025\n",
      "\tweight_decay: 0.001\n",
      "\tbatch_size: 64\n",
      "\tn_epochs: 3\n",
      "\tdata_dir: data\n",
      "\tcache_dir: /home/common/speech_phylo/models\n",
      "\tseed: 42\n"
     ]
    }
   ],
   "source": [
    "args = SimpleNamespace(\n",
    "    # Name of the dataset\n",
    "    dataset = \"nort3160\",\n",
    "    # Name of the backbone model\n",
    "    model_id = \"whisper_tiny\",\n",
    "    # Data type\n",
    "    dtype = \"speech\",\n",
    "    # Max audio duration\n",
    "    max_duration = 10,\n",
    "    # Whether to transform the data using Voice Activity Detection or not\n",
    "    transform = True,\n",
    "    # Device on which a torch.Tensor is or will be allocated\n",
    "    device = \"cuda:0\",\n",
    "    # Learning rate\n",
    "    lr = LR,\n",
    "    # Weight decay\n",
    "    weight_decay = WEIGHT_DECAY,\n",
    "    # Batch size\n",
    "    batch_size = BATCH_SIZE,\n",
    "    # Number of training epochs\n",
    "    n_epochs = N_EPOCHS,\n",
    "    # Path to main data folder path\n",
    "    data_dir = \"data\", # Change that folder if needed!\n",
    "    # Path where cached models are stored\n",
    "    cache_dir = \"/home/common/speech_phylo/models\",  # Change that folder if needed!\n",
    "    # Random seed\n",
    "    seed = RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for k, v in vars(args).items():\n",
    "    print(f\"\\t{k}: {v}\")\n",
    "\n",
    "if not (torch.cuda.is_available() and \"cuda\" in args.device):\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(args.seed, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading feature extractor...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "WhisperFeatureExtractor                            [1, 1, 384]               --\n",
       "├─Whisper: 1-1                                     --                        --\n",
       "│    └─AudioEncoder: 2-1                           --                        --\n",
       "│    │    └─Conv1d: 3-1                            [1, 384, 3000]            92,544\n",
       "│    │    └─Conv1d: 3-2                            [1, 384, 1500]            442,752\n",
       "│    │    └─ModuleList: 3-3                        --                        7,096,320\n",
       "│    │    └─LayerNorm: 3-4                         [1, 1500, 384]            768\n",
       "│    └─TextDecoder: 2-2                            --                        172,032\n",
       "│    │    └─Embedding: 3-5                         [1, 1, 384]               19,916,160\n",
       "│    │    └─ModuleList: 3-6                        --                        9,463,296\n",
       "│    │    └─LayerNorm: 3-7                         [1, 1, 384]               768\n",
       "====================================================================================================\n",
       "Total params: 37,184,640\n",
       "Trainable params: 37,184,640\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 978.24\n",
       "====================================================================================================\n",
       "Input size (MB): 0.06\n",
       "Forward/backward pass size (MB): 258.23\n",
       "Params size (MB): 148.05\n",
       "Estimated Total Size (MB): 406.34\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading feature extractor...\")\n",
    "feature_extractor = load_feature_extractor(\n",
    "    model_id=args.model_id,\n",
    "    cache_dir=args.cache_dir,\n",
    "    device=args.device,\n",
    ")\n",
    "\n",
    "summary(feature_extractor, input_size=(1, SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Loading processor...\n",
      "Dataset args:\n",
      "{'data_dir': 'data',\n",
      " 'dataset': 'nort3160',\n",
      " 'max_duration': 10,\n",
      " 'processor': <core.upstream.processing.WhisperProcessor object at 0x7faffc288dc0>,\n",
      " 'transform': Sequential(\n",
      "  (0): Vad()\n",
      "  (1): Trim()\n",
      "  (2): Pad()\n",
      ")}\n",
      "Data loader args:\n",
      "{'batch_size': 64, 'num_workers': 4, 'pin_memory': True}\n",
      "Loading data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing data...\")\n",
    "dataset_args = {\n",
    "    \"dataset\": args.dataset,\n",
    "    \"data_dir\": args.data_dir,\n",
    "}\n",
    "\n",
    "loader_args = {\n",
    "    \"num_workers\": 4,\n",
    "    \"batch_size\": args.batch_size,\n",
    "    \"pin_memory\": True,\n",
    "}\n",
    "\n",
    "if args.dtype == \"speech\":\n",
    "    print(\"Loading processor...\")\n",
    "    processor = load_processor(\n",
    "        model_id=args.model_id,\n",
    "        sr=SAMPLE_RATE,\n",
    "        cache_dir=args.cache_dir,\n",
    "    )\n",
    "\n",
    "    transform = load_transforms(\n",
    "        sr=SAMPLE_RATE, max_duration=args.max_duration, vad=args.transform\n",
    "    )\n",
    "\n",
    "    dataset_args = {\n",
    "        **dataset_args,\n",
    "        \"processor\": processor,\n",
    "        \"max_duration\": args.max_duration,\n",
    "        \"transform\": transform,\n",
    "    }\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "print(\"Dataset args:\")\n",
    "pprint(dataset_args)\n",
    "print(\"Data loader args:\")\n",
    "pprint(loader_args)\n",
    "\n",
    "print(\"Loading data...\")\n",
    "train_dataset, valid_dataset, test_dataset = load_data(**dataset_args)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, **loader_args)\n",
    "valid_loader = DataLoader(valid_dataset, shuffle=False, **loader_args)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, **loader_args)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing downstream classifier...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (classifier): Linear(in_features=384, out_features=5, bias=True)\n",
      "  (log_softmax): LogSoftmax(dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing downstream classifier...\")\n",
    "lit_mlp = LightningMLP(\n",
    "    feature_extractor=feature_extractor,\n",
    "    num_classes=len(train_dataset.label_encoder),\n",
    "    loss_fn=nn.NLLLoss(),\n",
    "    lr=args.lr,\n",
    "    weight_decay=args.weight_decay,\n",
    ")\n",
    "\n",
    "torch.compile(lit_mlp)\n",
    "\n",
    "print(lit_mlp.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mneclow\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/eval/wandb/run-20241028_083903-7zi2am3w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/neclow/mlops_project_eval_nort3160/runs/7zi2am3w' target=\"_blank\">misty-dew-11</a></strong> to <a href='https://wandb.ai/neclow/mlops_project_eval_nort3160' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/neclow/mlops_project_eval_nort3160' target=\"_blank\">https://wandb.ai/neclow/mlops_project_eval_nort3160</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/neclow/mlops_project_eval_nort3160/runs/7zi2am3w' target=\"_blank\">https://wandb.ai/neclow/mlops_project_eval_nort3160/runs/7zi2am3w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dir = f\"{args.data_dir}/eval\"\n",
    "os.makedirs(eval_dir, exist_ok=True)\n",
    "wandb_logger = WandbLogger(\n",
    "    project=f\"mlops_project_eval_{args.dataset}\", save_dir=eval_dir\n",
    ")\n",
    "\n",
    "wandb_logger.experiment.config.update(\n",
    "    {\n",
    "        \"model_id\": args.model_id,\n",
    "        \"max_duration\": args.max_duration,\n",
    "        \"transform\": args.transform,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name              | Type                    | Params | Mode \n",
      "----------------------------------------------------------------------\n",
      "0 | feature_extractor | WhisperFeatureExtractor | 37.2 M | eval \n",
      "1 | classifier        | MLP                     | 1.9 K  | train\n",
      "2 | loss_fn           | NLLLoss                 | 0      | train\n",
      "3 | train_metric      | MulticlassAccuracy      | 0      | train\n",
      "4 | valid_metric      | MulticlassAccuracy      | 0      | train\n",
      "5 | test_metric       | MulticlassAccuracy      | 0      | train\n",
      "----------------------------------------------------------------------\n",
      "37.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "37.2 M    Total params\n",
      "148.746   Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "131       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2410cb679814c6e90d262f1f52df7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0afdd44ab89d421986c6761497567c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a254409ba13a41e5a241a6fa283b24e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d5289f59124fe7b9860ad94fe663d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c98b904352413c87baa9e79a60fab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "if \"cuda\" in args.device:\n",
    "    accelerator = \"gpu\"\n",
    "    devices = [int(args.device.split(\":\")[-1])]\n",
    "else:\n",
    "    accelerator = \"cpu\"\n",
    "    devices = \"auto\"\n",
    "\n",
    "print(\"Start training!\")\n",
    "trainer = Trainer(\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    "    max_epochs=args.n_epochs,\n",
    "    enable_model_summary=True,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(monitor=\"valid_loss\", mode=\"min\", save_last=True),\n",
    "        TQDMProgressBar(),\n",
    "    ],\n",
    "    logger=wandb_logger,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model=lit_mlp,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=valid_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at data/eval/mlops_project_eval_nort3160/7zi2am3w/checkpoints/epoch=2-step=1386.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at data/eval/mlops_project_eval_nort3160/7zi2am3w/checkpoints/epoch=2-step=1386.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3941d9de7245289239b87cc2d282a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_metric        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8791059255599976     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_metric       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8791059255599976    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf09e7f0113c465c88db07f64fcc1211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆█</td></tr><tr><td>test_metric</td><td>▁</td></tr><tr><td>train_loss_epoch</td><td>█▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▃▄▃▂▄▂▂▃▃▁▂▂▃▂▂▂▃▂▂▁▂▂▁▂▁</td></tr><tr><td>train_metric_epoch</td><td>▁▇█</td></tr><tr><td>train_metric_step</td><td>▁▄▅▄▆▆▅█▇▆▆█▆▇▆▇▇▆▇▇▆▇▇▇█▅█</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇█████</td></tr><tr><td>valid_loss</td><td>█▄▁</td></tr><tr><td>valid_metric</td><td>▁▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>test_metric</td><td>0.87911</td></tr><tr><td>train_loss_epoch</td><td>0.25082</td></tr><tr><td>train_loss_step</td><td>0.12757</td></tr><tr><td>train_metric_epoch</td><td>0.90983</td></tr><tr><td>train_metric_step</td><td>0.95312</td></tr><tr><td>trainer/global_step</td><td>1386</td></tr><tr><td>valid_loss</td><td>0.39403</td></tr><tr><td>valid_metric</td><td>0.86456</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misty-dew-11</strong> at: <a href='https://wandb.ai/neclow/mlops_project_eval_nort3160/runs/7zi2am3w' target=\"_blank\">https://wandb.ai/neclow/mlops_project_eval_nort3160/runs/7zi2am3w</a><br/> View project at: <a href='https://wandb.ai/neclow/mlops_project_eval_nort3160' target=\"_blank\">https://wandb.ai/neclow/mlops_project_eval_nort3160</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/eval/wandb/run-20241028_083903-7zi2am3w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.test(\n",
    "    model=lit_mlp,\n",
    "    dataloaders=test_loader,\n",
    "    ckpt_path=\"best\",\n",
    ")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.api()\n",
    "\n",
    "run = api.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
